{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins>PHYS465: Coursework Exercise 2</ins>\n",
    "### Deadline Tuesday 27th January 2026 @ 4pm. \n",
    " * **Overall value: 20%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This coursework assesses the learning outcomes from Week 11, and in particular uncertainty estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Instructions</font>\n",
    " * Submit your work via Moodle.\n",
    " * You must submit a fully compiled `.ipynb` file which includes all codes required to replicate your results\n",
    "    * **Dont forget to check that every every cell runs before submitting**\n",
    "    * As part of the assessment your code will be run offline. \n",
    "    * You _must_ also respond to the mandatory GenAI self-assessment questionaire. \n",
    " * The estimated workload for this is 4-6 hours. \n",
    " \n",
    "### <font color='green'>Tips</font>\n",
    " * The last question of this exercise asks you write an interpretative statement.\n",
    "   * This assessment is designed to test your reflections on your learning and ability to summarise it succiently for a non-specialist audience. \n",
    "   * This question is worth 25% of the overall grade.\n",
    "      * To obtain this mark, additional work beyond the scope of the exercise is expected. All working must be included in the .ipynb submission.\n",
    "      * This additional work is at your own discretion. Any exploration of dataset beyond the scope of the worksheet presented is suitable.\n",
    "        * **NB**: the estimated workload for the entire worksheet is 4-6 hours.\n",
    "      * Markers have been asked to consider **both** additional work and insightful reflections.\n",
    "        * i.e. extensive work does not guarantee a high mark.\n",
    "   * The interpretative statement will be marked based on your reflections on your learning across the worksheet.\n",
    "      * It is expected to include both the values that you have found and an interpretation of it in the wider context.\n",
    "      * If you have not completed all exercises (or an extension) then the interpretative statement can focus on your learning:\n",
    "         * e.g. which techniques were difficult, and how might you address them.\n",
    " * 10% of marks are award for 'good coding practice'.\n",
    "   * A particular focus for this worksheet will be on annotations, such as doc-strings, comments and markdown notes.\n",
    "   * Pythonic coding is not expected, rather code that is accessible, and likely to be understandable **by you** after an extended break.\n",
    "   * Marks will be deducted for unnecessary steps (e.g. `for` loops) and inaccessible coding practices.\n",
    "   * Marks are also awarded for high quality visualisations, which be of extended focus later in the course.\n",
    "   * Explain all your reasoning for each step. Marks are given for explanations (in markup format) and discussion, as they evidence understanding of the analysis.\n",
    "\n",
    "### <font color='red'>WARNING</font>\n",
    " * This submission must be your own work. Please note the university's policy on plagiarism.\n",
    " * While it is acceptable (and indeed encouraged) to share ideas, you must ensure that you do not use other people's code or text, and that the reflections are your own.\n",
    " * It is acceptable to use GenAI tools (e.g. ChatGPT, Gemini) to produce code, but you must understand it. This module is an opportunity to learn key python libaries at the core of Data Science. Understanding these libaries now will enable you to use GenAI effectively when more advanced tasks are required.\n",
    " *  <font color='red'>**GenAI cannot be used to write the final interpretative statement**</font>\n",
    "   * Grammatical and syntax checks may be performed. \n",
    " * Should you use GenAI, then answer yes to the GenAI self-assessment. You will not be penalised for this. \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem\n",
    "\n",
    "The warming of the planet as caused by human activities is one of the key aspects of climate change. The influence of human activity can be traced through the atmospheric content of carbon dioxide (CO₂). \n",
    "\n",
    "This project uses atmospheric carbon dioxide (CO₂) measurements from the Mauna Loa Observatory in Hawaii, part of the Keeling Curve record that has monitored global background CO₂ levels continuously since 1958. The aim of the project is to model the long-term evolution of atmospheric CO₂, quantify the rate at which it is increasing, and test whether the growth rate itself is changing over time using statistical model fitting and χ²-based inference.\n",
    "\n",
    "Every year a new catalogue is released. The 2025 catalogue can be downloaded from here: `https://raw.githubusercontent.com/MatSmithAstro/phys465_2025_resources/main/coursework/datasets/co2_mlo_clean.csv` or through Moodle.\n",
    "\n",
    "This catalogue contains : \n",
    " * `decimal_year`: the date of observation\n",
    " * `co2_ppm`: the measured CO₂ content \n",
    " * `sigma_ppm` : the measured uncertainty \n",
    "\n",
    "See [here](http://gml.noaa.gov/ccgg/trends/) for additional details.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Exercise</font>\n",
    "\n",
    "1. Write down a suitable null hypothesis for the expected relationship between CO₂ levels and time (in years)\n",
    "   * _Hint: Consider not only trends but also the functional form that you are expecting._<div align=\"right\">**[1 mark]**</div><br>\n",
    " \n",
    "2. Load the dataset into a panda dataframe and visualise the data using matplotlib.\n",
    "   * Adjust the uncertainties to include a systematic error-floor of 3.5, in quadrature, for each point.  <div align=\"right\">**[4 marks]**</div><br>\n",
    "\n",
    "3. Considering only the data taken since the year 2000, fit a linear model. Visualise the results through the residuals from the best-fitting model. <div align=\"right\">**[4 marks]**</div><br>\n",
    "\n",
    "4. The dataset shows a strong seasonal dependence. To account for this we can consider the following model:\n",
    "   * $f(t) = a + bt + A\\sin(2\\pi t) + B\\cos(2\\pi t)$\n",
    "   * where $(a,b,A,B)$ are constants. To start with, we assume fixed values of $A=3.0$ and $B=-1.5$.\n",
    "   * Considering only the data taken since the year 2000:\n",
    "       1. Write a function to calculate $f(t)$ given input values.\n",
    "       2. Write a function to calculate both the $\\chi^2$ and $\\chi^2_\\text{red}$ statistics for this model.\n",
    "       3. Calculate the best-fit values of ($a$,$b$) and calculate the $\\chi^2_\\text{red}$ statistic between the data and the model considering uncertainties.\n",
    "       4. How do these values (and their uncertainties) compare to those determined above?\n",
    "       5. Visualise the data including results from the new model <div align=\"right\">**[8 marks]**</div><br>\n",
    "   \n",
    "5. Using existing tools, calculate the Spearman Rank correlation between the time and CO₂ levels <div align=\"right\">**[1 mark]**</div><br>\n",
    "\n",
    "6. For the time dependence term, calculate the $\\chi^2$ statistic between the data and the model considering multiple values of $b$\n",
    "   * Store the results in a table\n",
    "   * Plot the results by plotting the values of $b$ against the determined $\\chi^2$. \n",
    "   * From these results calculate the uncertainty on $b$.\n",
    "   * _Hint: You can use the uncertainty derived from curve-fitting to estimate the values to be looped over_\n",
    "   * _Hint: For speed, loop over no more than 300 values_\n",
    "   * _Hint: To calculate the uncertainty in $b$ consider the look-up table from the week 2 lecture notes, considering how many variables you are varying. <div align=\"right\">**[9 marks]**</div><br>\n",
    "\n",
    "7. Repeat the above test, but allow 2 parameters ($a$,$b$) to vary.\n",
    "   * Calculate the marginalised uncertainty on each.\n",
    "   * Plot the results as a contour plot.\n",
    "   * Visualise the results including your calculated uncertainties <div align=\"right\">**[12 marks]**</div><br>\n",
    "   \n",
    "8. **Extension and Interpretative Statement**. Write a short statement (300 words max) summarising a key result from this work and the consequence of it. Up to two figures may be included.\n",
    "   1. Suggestions for extensions include:\n",
    "      1. Consider all time-points and include an additional _acceleration_ term to be constrained\n",
    "      2. Vary all four parameters in the model and consider how the uncertainties vary, including the effect of the error-floor.\n",
    "      3. <font color='blue'>Note:</font> Your tests need not be exhaustive, but results should be accompanied with plots and analysis. <div align=\"right\">**[15 marks]**</div><br>\n",
    "   * **NB: The extension is worth 8 marks; the interpretative statement 7.** \n",
    "\n",
    "**Additional Marks** Marks will be awarded for notebooks, codes and plots that are well explained and well formatted. In particular, attention will be given to sensible variable names, easy to follow comments, notebook structure and informative visualisations. <div align=\"right\">**[6 marks]**</div><br>\n",
    "\n",
    "* <font color='white'>x</font> <div align=\"right\">Total available: **[60 marks]**</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
